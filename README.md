# Attack and defense methods
Inspired by [this repo](https://github.com/aleju/papers) and [ML Writing Month](https://docs.google.com/document/d/15o6m0I8g6O607mk5YPTh33Lu_aQYo7SpHhNSbLPQpWQ/mobilebasic?from=groupmessage#?utm_source=wechat_session&utm_medium=social&utm_oi=624560843380101120).  

# Papers
- `ATTACK` `ICLR 2013` [Evasion Attacks against Machine Learning at Test Time](./2013/Evasion_attacks_against_machine_learning_at_test_time.md)
- `ATTACK` `ICLR 2014` [Intriguing properties of neural networks](./2014/Intriguing_properties_of_neural_networks.md)
- `ATTACK` `ICLR 2015` [Explaining and Harnessing Adversarial Examples](./2015/Explaining_and_Harnessing_Adversarial_Examples.md)
- `ATTACK` `EuroS&P 2016` [The limitations of deep learning in adversarial settings](./2016/The_limitations_of_deep_learning_in_adversarial_settings.md)
- `ATTACK` `CVPR 2016` [Deepfool](./2016/DeepFool.md)
- `ATTACK` `SP 2016` [C&W Towards evaluating the robustness of neural networks](./2016/Toward_evaluating_the_robustness_of_neural_networks.md)
- `ATTACK` `Transferability` `Arxiv 2016` [Transferability in machine learning: from phenomena to black-box attacks using adversarial samples](./2016/Transferability_in_machine_learning.md)
- `ATTACK` `Transferability` `CVPR 2019` [Feature Space Perturbations Yield More Transferable Adversarial Examples](./2019/Feature_Space_Perturbations_Yield_More_Transferable_Adversarial_Examples.md)
- `ATTACK` `Transferability` `ICLR 2017` [Delving into Transferable Adversarial Examples and Black-box Attacks](./2017/Delving_into_Transferable_Adversarial_Examples_and_Black-box_Attacks.md)