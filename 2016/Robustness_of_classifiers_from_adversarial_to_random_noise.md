```
@inproceedings{DBLP:conf/nips/FawziMF16,
author = {Fawzi, Alhussein and Moosavi-Dezfooli, Seyed-Mohsen and Frossard, Pascal},
booktitle = {Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain},
editor = {Lee, Daniel D and Sugiyama, Masashi and von Luxburg, Ulrike and Guyon, Isabelle and Garnett, Roman},
pages = {1624--1632},
title = {{Robustness of classifiers: from adversarial to random noise}},
url = {http://papers.nips.cc/paper/6331-robustness-of-classifiers-from-adversarial-to-random-noise},
year = {2016}
}
```
worst-case perturbations mean adversarial perturbations.

They quantify the robustness of nonlinear classifiers in two practical noise regimes, **random** and **semi-random** noise regimes.
In the random noise regime, datapoints are perturbed by noise with random direction in the input space. 
In the semi-random refime generalizes this model to random subspaces of arbitrary dimension, where a worst-case perturbation is sought with the subspace. 