```
@inproceedings{DBLP:conf/icml/LiLWZG19,
author = {Li, Yandong and Li, Lijun and Wang, Liqiang and Zhang, Tong and Gong, Boqing},
booktitle = {Proceedings of the 36th International Conference on Machine Learning, {\{}ICML{\}} 2019, 9-15 June 2019, Long Beach, California, {\{}USA{\}}},
editor = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
pages = {3866--3876},
publisher = {PMLR},
series = {Proceedings of Machine Learning Research},
title = {{{\{}NATTACK:{\}} Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks}},
url = {http://proceedings.mlr.press/v97/li19g.html},
volume = {97},
year = {2019}
}
```

Rejected by ICLR 2019 but accepted by ICML 2019. Find the [Review from ICLR](https://openreview.net/forum?id=ryeoxnRqKQ).

I did not read it through and got no idea. According to the review, it shares many similarities with [1].


[1] Ilyas, A., Engstrom, L., Athalye, A., & Lin, J. (2018). Black-box Adversarial Attacks with Limited Queries and Information. In J. Dy & A. Krause (Eds.), Proceedings of the 35th International Conference on Machine Learning (pp. 2137â€“2146). Retrieved from http://proceedings.mlr.press/v80/ilyas18a.html